{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import stats, norm, skew\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scipy.special import boxcox1p\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(2)\n",
    "plt.style.use('ggplot') \n",
    "matplotlib.rcParams['figure.figsize'] = (10,10)\n",
    "plt.rcParams['font.size'] = 20 #font size\n",
    "plt.rcParams['axes.linewidth'] = 1.5 #axis setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"./train_radius.csv\")\n",
    "test = pd.read_csv(\"./test_radius.csv\")\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d78ba4a279f81c6e5356b862224499af3311cece"
   },
   "outputs": [],
   "source": [
    "train = train.drop(['Id',\"SQUARE\",\"X\",\"Y\"], axis=1)\n",
    "test = test.drop([\"SQUARE\",\"X\",\"Y\"], axis=1)\n",
    "\n",
    "train[\"GBA\"] = np.log1p(train[\"GBA\"])\n",
    "test[\"GBA\"] = np.log1p(test[\"GBA\"])\n",
    "train[\"LIVING_GBA\"] = np.log1p(train[\"LIVING_GBA\"])\n",
    "test[\"LIVING_GBA\"] = np.log1p(test[\"LIVING_GBA\"])\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1241b9b573a8f6115980ac330948c2bbe5620ed"
   },
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2a1991ee4a69b6f8df05fd6b40732096dd1b55e"
   },
   "outputs": [],
   "source": [
    "cols_with_none_as_nan = [\n",
    "    \"HEAT\", \n",
    "    \"AC\",\n",
    "    \"STYLE\",\n",
    "    \"STRUCT\",\n",
    "    \"GRADE\",\n",
    "    \"CNDTN\",\n",
    "    \"EXTWALL\",\n",
    "    \"ROOF\",\n",
    "    \"INTWALL\",\n",
    "    \"FULLADDRESS\",\n",
    "    \"CITY\",\n",
    "    \"STATE\",\n",
    "    \"NATIONALGRID\",\n",
    "    \"ASSESSMENT_SUBNBHD\",\n",
    "    \"CENSUS_BLOCK\",\n",
    "    \"QUADRANT\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# fill missing text fields with a default string\n",
    "object_columns = train.select_dtypes(include=[object])\n",
    "test_object_columns = test.select_dtypes(include=[object])\n",
    "\n",
    "# for these colunms the string 'None' will be inserted in place of nan\n",
    "for col in cols_with_none_as_nan:\n",
    "    object_columns.loc[:, col] = object_columns.loc[:, col].fillna('None')\n",
    "    test_object_columns.loc[:, col] = test_object_columns.loc[:, col].fillna('None')\n",
    "\n",
    "remaining_fix = object_columns.isnull().sum()\n",
    "print('Fixes remaining on train set\\n', remaining_fix[remaining_fix>0])\n",
    "\n",
    "remaining_fix = test_object_columns.isnull().sum()\n",
    "print('Fixes remaining on test set\\n',remaining_fix[remaining_fix>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "040a3f5ed4709eb84be7731bc3d9e210f153e0ff"
   },
   "outputs": [],
   "source": [
    "numeric_columns = train.select_dtypes(include=[int, float])\n",
    "\n",
    "remaining_fix = numeric_columns.isnull().sum()\n",
    "print('Fixes remaining on train set\\n',remaining_fix[remaining_fix>0])\n",
    "\n",
    "test_numeric_columns = test.select_dtypes(include=[int, float])\n",
    "\n",
    "remaining_fix = test_numeric_columns.isnull().sum()\n",
    "print('Fixes remaining on test set\\n',remaining_fix[remaining_fix>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92685802f7cdf157674988ea46e41ae367e6fc24",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols_with_zero_as_nan = ['CMPLX_NUM',\n",
    "                         'YR_RMDL',\n",
    "                         'KITCHENS',\n",
    "                         'NUM_UNITS',\n",
    "                         'STORIES',\n",
    "                         \"AYB\",\n",
    "                         \"GBA\",\n",
    "                         \"LIVING_GBA\",\n",
    "                         \"GBA_ROOMS\",\n",
    "                         \"LIVING_GBA_ROOMS\",\n",
    "                         \"LANDAREA_ROOMS\"\n",
    "                        ]\n",
    "\n",
    "cols_with_mean_as_nan = [\n",
    "                        ]\n",
    "\n",
    "\n",
    "# for these colunms a zero will be inserted in place of nan\n",
    "for col in cols_with_zero_as_nan:\n",
    "    numeric_columns.loc[:, col] = numeric_columns.loc[:, col].fillna(0)\n",
    "    test_numeric_columns.loc[:, col] = test_numeric_columns.loc[:, col].fillna(0)\n",
    "    \n",
    "# for these colunms the mean will be inserted in place of nan\n",
    "for col in cols_with_mean_as_nan:\n",
    "    numeric_columns.loc[:, col] = numeric_columns.loc[:, col].fillna(numeric_columns[col].mean())\n",
    "    test_numeric_columns.loc[:, col] = test_numeric_columns.loc[:, col].fillna(test_numeric_columns[col].mean())\n",
    "\n",
    "\n",
    "remaining_fix = numeric_columns.isnull().sum()\n",
    "print('Fixes remaining on train set\\n',remaining_fix[remaining_fix>0])\n",
    "\n",
    "remaining_fix = test_numeric_columns.isnull().sum()\n",
    "print('Fixes remaining on test set\\n',remaining_fix[remaining_fix>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b383c47695c2d078d7e95c9ee0406217c2f5e1cc",
    "collapsed": true
   },
   "source": [
    "object_dm = pd.get_dummies(object_columns, drop_first=True, dummy_na=True)\n",
    "test_object_dm = pd.get_dummies(test_object_columns, drop_first=True, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c818563a6db4a9935ec100a157d783c4d1860ac1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fix_skewness(dataframe):\n",
    "    skewed_feats = dataframe.apply(lambda x: abs(skew(x.dropna()))).sort_values(ascending=False)\n",
    "    skewness = pd.DataFrame({'Skew': skewed_feats})\n",
    "    skewness = skewness[abs(skewness) > 0.75].dropna()\n",
    "    print(\"There are {} skewed numerical features to transform\".format(skewness.shape[0]))\n",
    "    print(\"\\nSkew > .75 in numerical features: \\n\")\n",
    "    print(skewness)\n",
    "    # Fix skewness\n",
    "    skewed_features = skewness.index\n",
    "    lam = 0.15\n",
    "    for feat in skewed_features:\n",
    "        if feat == 'PRICE': continue\n",
    "        dataframe[feat] = boxcox1p(dataframe[feat], lam)\n",
    "    print('Fixed skewness')\n",
    "\n",
    "fix_skewness(numeric_columns)\n",
    "fix_skewness(test_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10115634cb2fe617586f86be732c3fb707099bc7"
   },
   "outputs": [],
   "source": [
    "strings = np.array([])\n",
    "for c in object_columns.columns:\n",
    "    strings = np.append(strings, pd.unique(object_columns[c].values))\n",
    "\n",
    "for c in test_object_columns.columns:\n",
    "    strings = np.append(strings, pd.unique(test_object_columns[c].values))\n",
    "\n",
    "print(len(strings), 'distinct labels generated')\n",
    "\n",
    "labeler = LabelEncoder()\n",
    "labeler.fit(strings.astype(\"str\"))\n",
    "\n",
    "for c in object_columns.columns:\n",
    "    object_columns.loc[:,c] = labeler.transform(object_columns.loc[:,c])\n",
    "    test_object_columns.loc[:,c] = labeler.transform(test_object_columns.loc[:,c])\n",
    "\n",
    "object_columns[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e926d5b17ed019dcc87f12e17134e8d8f57ca03"
   },
   "outputs": [],
   "source": [
    "# final train dataset\n",
    "train_ds = object_columns.join(numeric_columns)\n",
    "train_ds[\"PRICE\"] = np.log1p(train_ds[\"PRICE\"])\n",
    "\n",
    "# test dataset\n",
    "test_ds = test_object_columns.join(test_numeric_columns)\n",
    "\n",
    "#correlation matrix\n",
    "corrmat = train_ds.corr()['PRICE']\n",
    "print(corrmat)\n",
    "#f, ax = plt.subplots(figsize=(12, 9))\n",
    "#sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "\n",
    "best_columns = corrmat[abs(corrmat) > 0.0].index\n",
    "train_ds = train_ds[best_columns]\n",
    "test_ds = test_ds[best_columns.drop('PRICE')]\n",
    "best_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8bc3f26c68681b09c4de60fc0b247f4a39c4892",
    "collapsed": true
   },
   "source": [
    "train_ds = pd.concat([train_ds, object_dm], axis=1)\n",
    "test_ds = pd.concat([test_ds, test_object_dm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53060d55104e9a032268ee0dcac27a60432e567f"
   },
   "outputs": [],
   "source": [
    "X_train = (train_ds.values[:,:-1])\n",
    "y_train = np.asarray([[t] for t in (train_ds.values[:,-1])])\n",
    "X_test = test_ds.values\n",
    "\n",
    "print('Training set features shape', X_train.shape)\n",
    "print('Training set labels shape', y_train.shape)\n",
    "print('Test set shape', test_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a200d7e95d1b58bab46d1f013db1af9a8bea091",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "transformer = RobustScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(transformer.transform(X_train))\n",
    "X_test = pd.DataFrame(transformer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c8d2bfd5e8301db389812fdcb5d37f33dabe5b8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(depth, learning_rate, n_estimators, model_type=\"xgb\"):\n",
    "    if model_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                                 learning_rate=learning_rate, max_depth=depth, \n",
    "                                 min_child_weight=1.7817, n_estimators=n_estimators,\n",
    "                                 reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                                 subsample=0.5213, silent=1,\n",
    "                                 random_state =7, nthread = -1)\n",
    "    if model_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(colsample_bytree=0.4603, min_gain_to_split=0.0468, \n",
    "                                 learning_rate=learning_rate, max_depth=depth, \n",
    "                                 min_child_weight=1.7817, n_estimators=n_estimators,\n",
    "                                 reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                                 subsample=0.5213, silent=1,\n",
    "                                 random_state =7, nthread = -1)\n",
    "        \n",
    "    score = rmsle_cv(model)\n",
    "    print(model_type, \" score: depth={:d} lr={:.2f} est={:d} -> mean:{:.5f} std:{:.4f}\".format(depth, learning_rate, n_estimators, score.mean(), score.std()))\n",
    "    return score\n",
    "\n",
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train.flatten(), scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f4ed5f2ddba8a47489a5e331a35cc3282cf395f"
   },
   "source": [
    "result = []\n",
    "for depth in range(2, 6):\n",
    "    for learning_rate in range(100, 500, 100):\n",
    "        for n_estimators in range(4000, 6000, 500):\n",
    "            score = train_model(depth, learning_rate/100, n_estimators, model_type='lgb')\n",
    "            result.append([depth, learning_rate/100, n_estimators, score.mean(), score.std()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b92d84b5e4fa7ef3ef37d2292e9cacd39edfd6cf"
   },
   "source": [
    "# check results\n",
    "result = pd.DataFrame(result, columns=['depth', 'learning_rate', 'n_estimators', 'score_mean', 'score_std'])\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b838c156d062bc82b1c551c367ac7188da390cd6"
   },
   "source": [
    "best = np.argmin(result['score_mean'].values)\n",
    "print('Best params = \\n', result.iloc[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "3ece27cb6941092481f88caad90267dd0592e4fd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc32fe821eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model_lgb = lgb.LGBMRegressor(num_leaves=8,colsample_bytree=0.4603,learning_rate=learning_rate, max_depth=depth, \n\u001b[0m\u001b[1;32m     13\u001b[0m                          \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.7817\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                          \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8571\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "# train with the best parameters\n",
    "\n",
    "#depth = int(result.iloc[best]['depth'])\n",
    "#learning_rate = result.iloc[best]['learning_rate']\n",
    "#n_estimators = int(result.iloc[best]['n_estimators'])\n",
    "\n",
    "\n",
    "depth = 5\n",
    "learning_rate = 0.5\n",
    "n_estimators = 1000\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(num_leaves=8,colsample_bytree=0.4603,learning_rate=learning_rate, max_depth=depth, \n",
    "                         min_child_weight=1.7817, n_estimators=n_estimators,\n",
    "                         reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                         subsample=0.5213, silent=1,\n",
    "                         random_state = 6, nthread = -1)\n",
    "\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"lgb score: depth={:d} lr={:.2f} est={:d} -> mean:{:.5f} std:{:.4f}\".format(depth, learning_rate, n_estimators, score.mean(), score.std()))\n",
    "\n",
    "model_lgb.fit(X_train, y_train.flatten())\n",
    "y_pred = model_lgb.predict(X_train)\n",
    "\n",
    "print('RMSLE LGB = ', rmsle(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "deeef29a8243de1961f76eaeeda652477d197868"
   },
   "outputs": [],
   "source": [
    "print(model_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb5bd25181cc536c42f4602892af6aea992518bd"
   },
   "source": [
    "plt.scatter(np.expm1(y_train), np.expm1(y_pred))\n",
    "#plt.xlim(0, 100_000_00)\n",
    "#plt.ylim(0, 100_000_00)\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('predicted')\n",
    "plt.grid()\n",
    "#plt.plot([(0, 0), (10_000_000, 10_000_000)], [(0, 0), (10_000_000, 10_000_000)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3be49e4dccf70a939bb85be835548e661b2046b",
    "scrolled": false
   },
   "source": [
    "predictors = [x for x in train_ds.columns if x not in [\"PRICE\", \"Id\"]]\n",
    "feat_imp = pd.Series(model_lgb.feature_importances_, predictors).sort_values(ascending=False)\n",
    "sns.set_palette(\"husl\")\n",
    "sns.barplot( feat_imp.head(20).values,feat_imp.head(20).index)\n",
    "plt.title('Top10 Feature Importances')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "abeb4803f1f58dca4b85ec95cd8f2219a6afed4c"
   },
   "source": [
    "result = []\n",
    "for depth in range(2, 6):\n",
    "    for learning_rate in range(100, 500, 100):\n",
    "        for n_estimators in range(4000, 6000, 500):\n",
    "            score = train_model(depth, learning_rate/100, n_estimators, model_type='lgb')\n",
    "            result.append([depth, learning_rate/100, n_estimators, score.mean(), score.std()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51e245b61ab6e1220b03891c8b1355f422f1eee5"
   },
   "source": [
    "# check results\n",
    "result = pd.DataFrame(result, columns=['depth', 'learning_rate', 'n_estimators', 'score_mean', 'score_std'])\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1565da9285ae21c8e67d43bf224484a19a7f8fe7"
   },
   "source": [
    "best = np.argmin(result['score_mean'].values)\n",
    "print('Best params = \\n', result.iloc[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6189d87b0addab89acb22229bc55b2f151e55094",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train with the best parameters\n",
    "\n",
    "#depth = int(result.iloc[best]['depth'])\n",
    "#learning_rate = result.iloc[best]['learning_rate']\n",
    "#n_estimators = int(result.iloc[best]['n_estimators'])\n",
    "\n",
    "\n",
    "depth = 5\n",
    "learning_rate = 0.5\n",
    "n_estimators = 1000\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(learning_rate=learning_rate, max_depth=depth, \n",
    "                         min_child_weight=1.7817, n_estimators=n_estimators,silent=1,\n",
    "                         random_state =7, nthread = -1)\n",
    "\n",
    "\n",
    "\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"XGB score: depth={:d} lr={:.2f} est={:d} -> mean:{:.5f} std:{:.4f}\".format(depth, learning_rate, n_estimators, score.mean(), score.std()))\n",
    "\n",
    "model_xgb.fit(X_train, y_train.flatten())\n",
    "y_pred = model_xgb.predict(X_train)\n",
    "\n",
    "print('RMSLE XGB = ', rmsle(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6ed58cc26cd0b49f22bc6839919eeb74682ae0f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.expm1(y_train), np.expm1(y_pred))\n",
    "#plt.xlim(0, 100_000_000)\n",
    "#plt.ylim(0, 100_000_000)\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('predicted')\n",
    "plt.grid()\n",
    "plt.plot([(0, 0), (10_000_000, 10_000_000)], [(0, 0), (10_000_000, 10_000_000)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08eb63a9a0fa25eceb6a7c016b04159565445126",
    "collapsed": true
   },
   "source": [
    "predictors = [x for x in train_ds.columns if x not in [\"PRICE\", \"Id\"]]\n",
    "feat_imp = pd.Series(model_lgb.feature_importances_, predictors).sort_values(ascending=False)\n",
    "sns.set_palette(\"husl\")\n",
    "sns.barplot( feat_imp.head(20).values,feat_imp.head(20).index)\n",
    "plt.title('Top10 Feature Importances')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40bd6c3286f840c4d27d5bfc058de38fdd9ba4d6",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg_predict = (model_lgb.predict(X_train) + model_xgb.predict(X_train)) / 2\n",
    "y_pred = avg_predict\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(np.expm1(y_train), np.expm1(y_pred))\n",
    "plt.xlim(0, 200_000_000)\n",
    "plt.ylim(0, 200_000_000)\n",
    "plt.xlabel('actual', fontsize=26)\n",
    "plt.ylabel('predicted', fontsize=26)\n",
    "plt.plot([(0, 0), (10_000_000, 10_000_000)], [(0, 0), (10_000_000, 10_000_000)])\n",
    "plt.show()\n",
    "\n",
    "print('RMSLE averaged = ', rmsle(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d03f1d94cfaafeebcf253e57098843deee750ab7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission\n",
    "print(np.expm1(model_xgb.predict(X_test)[0:5]))\n",
    "print(np.expm1(model_lgb.predict(X_test)[0:5]))\n",
    "avg_predict = (model_xgb.predict(X_test) + model_lgb.predict(X_test)) / 2\n",
    "subm_predict = np.expm1(avg_predict)\n",
    "\n",
    "dsubm_predict = pd.DataFrame()\n",
    "dsubm_predict['Id'] = test.values[:,0]\n",
    "dsubm_predict[\"PRICE\"] = pd.DataFrame(subm_predict)\n",
    "\n",
    "dsubm_predict.to_csv('submission.csv', index=False)\n",
    "dsubm_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission\n",
    "print(np.expm1(model_lgb.predict(X_test)[0:5]))\n",
    "avg_predict =  model_lgb.predict(X_test)\n",
    "dsubm_predict = np.expm1(avg_predict)\n",
    "\n",
    "dsubm_predict = pd.DataFrame()\n",
    "dsubm_predict['Id'] = test.values[:,0]\n",
    "dsubm_predict[\"PRICE\"] = pd.DataFrame(subm_predict)\n",
    "\n",
    "dsubm_predict.to_csv('submission.csv', index=False)\n",
    "dsubm_predict[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4fff9fcb2e88562a1a9aa4b62257a77431d12505",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsubm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4e186c1e76b8430cc4c5312149c63d723ccc6ff",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
